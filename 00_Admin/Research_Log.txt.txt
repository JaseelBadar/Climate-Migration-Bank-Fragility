======================================================================
RESEARCH LOG - Climate Change, Migration, and Bank Fragility
======================================================================
Project: Climate-induced migration effects on banking sector stability
Period: December 2025 - Present
Author: Jaseel Badar
Location: E:\Climate-Migration-Bank-Fragility\
======================================================================

======================================================================
2025-12-30 to 2025-12-31: Phase 1 - Project Initialization & Environment Setup
======================================================================
Goal: Set up computational environment and project structure

Environment Setup:
- Created conda environment: research_env
- Installed core packages: pandas, geopandas, rasterio, matplotlib, statsmodels
- Python 3.10.19 on Windows 11
- VS Code configured as primary IDE

Project Structure Created:
- 00_Admin/ (documentation, logs)
- 01_Data_Raw/ (original data, never modified)
- 02_Data_Intermediate/ (intermediate processing outputs)
- 03_Data_Clean/ (cleaned datasets for analysis)
- 04_Code/ (all Python scripts)
- 05_Outputs/ (regression outputs, figures)
- 06_Drafts/ (paper drafts)

GitHub Repository:
- Initialized local Git repository
- Created .gitignore (excludes large files / prevents repo bloat)
- First commit: "Initial project structure"

Key Decisions:
- Manual data download approach (API attempts for VIIRS failed)
- Focus on 2015-2024 period (10-year panel)

Status: Environment ready, awaiting data download
Next: Download RBI, EM-DAT, VIIRS datasets

======================================================================
2026-01-02 (Thu): Phase 2 - Data Acquisition (Day 1)
======================================================================
Goal: Download all three core datasets

Data Sources Acquired:

1. RBI District Banking Statistics (BSR-2)
   Location: 01_Data_Raw/RBI_Bank_Data/
   Files downloaded:
   - RBI_Deposits_2004_2017.xlsx (historical baseline)
   - RBI_Deposits_2017_2022.xlsx (5-year mid-period)
   - RBI_Deposits_2023_2024.xlsx (recent data)
   Source: Reserve Bank of India official portal
   Coverage: All districts, quarterly snapshots
   Variables: Deposits by population group (Rural/Semi-urban/Urban/Metro)

2. EM-DAT Disaster Database
   Location: 01_Data_Raw/EMDAT_Disasters/
   File: public_emdat_custom_request_2026-01-02_c149ea93-8fbf-4f6e-a8f6-3b41cc622ed0.xlsx
   Source: Centre for Research on Epidemiology of Disasters (CRED)
   Filters applied: Country=India, Disaster Type=Flood, Period=2015-2024
   Events: 70 flood events (later corrected to 69 after inspection)
   Variables: Location, dates, deaths, affected population, damage estimates

3. VIIRS Nighttime Lights (Test Tile)
   Location: 01_Data_Raw/VIIRS_NightLights/
   Test file: SVDNB_npp_20230101-20230131_75N060E_vcmcfg_v10_c202302080600
   Files extracted: .avg_rade9h.tif (avg radiance), .cvg.tif, .cf_cvg.tif
   Source: Colorado School of Mines Earth Observation Group
   Tile: 75N060E (covers all of India)
   Period tested: January 2023 (1 month)
   Note: Full download (120 months, 2015-2024) deferred to Phase 3d

Key Decisions:
- VIIRS Microsoft Planetary Computer API failed (returned 0 items)
- Pivoted to manual download from Colorado School of Mines
- Downloaded single test tile to validate format before bulk download
- RBI files span different periods, will require concatenation

Commits: 3 (data folder structure + download documentation)
Status: Phase 2 complete
Next: Phase 3a literature acquisition + Phase 3c data inspection (merge feasibility)

======================================================================
2026-01-05 (Sun): Phase 3a - Literature Acquisition
======================================================================
Goal: Build a defensible novelty baseline and assemble the core bibliography

Actions Completed:
- Searched Google Scholar, SSRN, NBER using targeted keywords
- Used Harvard HOLLIS to bypass paywalls for locked papers
- Downloaded ~15-18 papers via Zotero Chrome Connector
- Organized PDFs in 00_Admin/Literature_PDFs folder
- Fixed Zotero metadata (missing authors/dates)
- Created LiteratureTracker.xlsx with table structure

Status: Papers acquired. Ready for gap analysis reading/annotation.
Next: Phase 3b - Fill LiteratureTracker.xlsx using abstracts/intros/conclusions

======================================================================
2026-01-06 (Mon): Phase 3b - Gap Analysis
======================================================================
Goal: Confirm novelty and define “what the literature missed” in a structured way

Actions Completed:
- Read abstracts / key intro paragraphs / conclusions for the collected paper set (~15-18 papers)
- Filled LiteratureTracker.xlsx with multi-dimensional gap analysis:
  - Geographic gaps (India district-level evidence scarce / inconsistent)
  - Methodological gaps (satellite lights often used for activity proxies; migration mechanism under-tested)
  - Temporal gaps (many designs not aligned to disaster timing / dynamic panels)
  - Mechanistic gaps (banking stability often framed via credit risk; deposit/liquidity channel underemphasized)
- Confirmed novelty positioning: No paper in the reviewed set establishes the full chain:
  Climate shock → (migration proxied by VIIRS) → district-level deposit stress in India

Status: Literature phase complete. Novelty defense ready.
Next: Phase 3c - Formalize hypotheses/codebook and begin data inspection scripts

======================================================================
2026-01-07 (Tue): Phase 3c Day 0 - Conceptual Work (Mobile Only)
======================================================================
Goal: Maintain momentum and lock “definitions + hypotheses” before coding

Actions Completed:
- Laptop unavailable - executed mobile research tasks to maintain momentum
- Created Variables_Codebook_v1.md:
  - Defined variable families (outcomes, treatments, controls, networks, panel structure)
  - Defined transformations to be used in code (e.g., log changes, quarterly aggregation targets)
- Created Hypotheses_Formal_v1.md:
  - H1: Flood events → Decline in nighttime light intensity (VIIRS)
  - H2: Nighttime light decline → Decline in formal bank deposits
  - H3: Deposit decline → Increased reliance on shadow banking (timing analysis)
  - H4: Banking stress exhibits spatial contagion through district networks
- Both documents specify measurement intentions (time aggregation, geographic unit, sign expectations)

Status: Codebook + hypotheses locked. Ready to implement inspection scripts on laptop.
Next: Phase 3c Day 1 (Jan 8) - RBI/EM-DAT/VIIRS inspection scripts + merge feasibility validation

======================================================================
2026-01-08 (Wed) 19:00-21:30 PM IST: Phase 3c Day 1 - Data Inspection
======================================================================
Goal: Validate merge feasibility across 3 datasets (RBI, EM-DAT, VIIRS)

Scripts Created:
1. 02_inspect_rbi.py: RBI deposit structure inspection
   - 762 unique districts (UPPERCASE, hyphenated names)
   - 11 quarters (2023Q1-2025Q2), 4 population groups per district
   - Deposit columns at indices 7,10,13,16,19,22,25,28,31,34,37
   - Aggregation required: GROUP BY district, SUM across population groups

2. 03_inspect_emdat.py: EM-DAT flood event inspection
   - 69 flood events (2015-2024)
   - 35 events (50.7%) have district-level Admin Units data → 147 districts
   - 34 events (49.3%) have empty Admin Units (requires Location text parsing)
   - Severity measure: No. Affected (73.9% coverage)
   - Date structure: Complete, convertible to quarters

3. 04_inspect_viirs.py: VIIRS nighttime lights validation
   - Test tile (Jan 2023, 75N060E): 1.93 GB GeoTIFF, 28800×18000 pixels
   - India fully covered (60-180°E, 0-75°N extent)
   - Radiance range: 0-57.24 nW/cm²/sr (mean 0.87, median 0.50)
   - Resolution: 15 arc-second (~463m at equator)
   - Data validity: CONFIRMED

Key Findings:
- RBI: 762 districts ready for merge (standardized naming)
- EM-DAT: Geographic precision heterogeneous (50% district-level, 50% state-level)
- VIIRS: Production-ready, H1/H2 testable with district aggregation
- Expected treatment/control split: ~150 flooded districts, ~600 non-flooded
- Update (Jan 9): Admin Units are present for 57/69 events once parsed correctly (adm2_name districts + adm1_name states); only 12/69 require Location parsing.

Next Session (Phase 3c Day 2 - Jan 9):
- Parse EM-DAT Location text for missing 34 events
- Build district name harmonization crosswalk (fuzzy matching)
- Test VIIRS spatial subsetting (extract India bounding box)

Commits: 4 scripts (01_download_viirs placeholder, 02-04 inspection scripts)
Status: Phase 3c Day 1 complete

======================================================================
2026-01-09 (Fri) 17:45-18:40 PM IST: Phase 3c Day 2 - District Boundaries + EM-DAT Parsing
======================================================================
Goal: Begin district harmonization by locking district boundary polygons and extracting district/state labels from EM-DAT floods.

A) District boundary dataset acquired (GADM)
- Downloaded: gadm41_IND_shp.zip (GADM v4.1, India)
- Extracted to: 01_Data_Raw/District_Boundaries/
- Validated via geopandas load test:
  - gadm41_IND_2.shp loaded successfully
  - 676 district polygons
  - Key columns confirmed: NAME_1 (state), NAME_2 (district), geometry

B) EM-DAT district/state extraction completed
- Script created: 04_Code/06_parse_emdat_locations.py
- Outputs:
  - 02_Data_Intermediate/emdat_districts_parsed.csv
  - 05_Outputs/Logs/06_parse_emdat_log.txt
- Results:
  - Total flood events in file: 69
  - Events with usable Admin Units (adm2_name districts or fallback adm1_name states): 57 (82.6%)
  - Events missing Admin Units: 12 (17.4%) → parsed from free-text Location field
  - Geographic labels produced for all 69 events (districts and/or states)

C) Output verification
- Script created: 04_Code/07_check_output.py
- Verified:
  - emdat_districts_parsed.csv loads
  - 69/69 events have non-empty districts_final_str

Notes / Known issues
- Parsed Location text contains typos and non-district tokens in some cases (e.g., “Administrative unit not available”, “Itanagar distrci”, “Meghalaya states”).
- These will be handled during crosswalk cleaning (manual corrections + fuzzy match).

Status: District boundaries locked; EM-DAT geographic extraction complete.
Next: Build district name crosswalk (RBI ↔ GADM ↔ EM-DAT) and then generate flood exposure panel (Rule A vs Rule B).

======================================================================
2026-01-10 (Sat) 22:45-23:35 PM IST: Phase 3c Day 2.5 - Documentation Hygiene (No Coding)
======================================================================
Goal: Lock documentation language to avoid overclaiming and ensure repo docs match the actual folder structure and current phase status.

Actions Completed
A) Claim discipline updates (documentation-only)
- Core_Claims.docx: softened “first causal evidence” phrasing to “aims to provide” and made propagation wording explicitly conditional on data feasibility.
- Literature_Tracker.xlsx: softened top novelty claim from “establishes first causal evidence” to “aims to provide causal evidence consistent with.”

B) Identification / IV discipline wording (documentation-only)
- Hypotheses_Formal_v1.1.md: rewrote the H2b exclusion restriction paragraph to frame it as an identifying assumption with explicit threats (e.g., direct banking-operations disruption), without changing the empirical plan.

C) Codebook consistency (documentation-only)
- Variables_Codebook_and_Coding_Protocol_v1.1.md:
  - Updated the District Polygons status to reflect that GADM v4.1 Level-2 district boundaries are already downloaded and validated (676 districts).
  - Removed any stray [file:*] artifacts left from prior drafting.

D) README cleanup (documentation-only)
- README.md:
  - Removed [file:*] artifacts.
  - Updated repo layout to reflect current v1.1 filenames and current pipeline state.
  - Preserved RBI file extensions as .xlsx (local saved format).
  - Fixed markdown formatting issues (closed code fences) and removed duplicated outdated “Last Updated/Phase” footer lines.

Commits (documentation-only)
- Commit: “Tighten Core Claims wording”
- Commit: “Update novelty statement in Literature Tracker”
- Commit: “Clarify IV assumption language (Hypotheses v1.1)”
- Commit: “Update codebook: GADM obtained + cleanup”
- Commit: “README cleanup: consistency + formatting”

Status:
Documentation is now aligned with the current project state (Phase 3c Day 2 complete; crosswalk pending). No data or code changes were made in this session.

Next:
Phase 3c Day 3: Build district-name crosswalk (RBI ↔ GADM ↔ EM-DAT), generate district_crosswalk_draft.csv, and produce crosswalk log with match-rate stop condition check.

======================================================================
END OF LOG - Last Updated: 2026-01-10 23:35 PM IST
======================================================================
