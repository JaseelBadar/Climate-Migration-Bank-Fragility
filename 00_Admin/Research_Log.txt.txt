======================================================================
RESEARCH LOG - Climate Shocks, Displacement, and Bank Liquidity Risk: Evidence from Night-Lights in India (2015–2024)
======================================================================
Project: Climate-induced migration effects on banking sector stability
Period: December 2025 - Present
Author: Jaseel Badar
Location: E:\Climate-Migration-Bank-Fragility\
======================================================================

======================================================================
2025-12-30 to 2025-12-31: Phase 1 - Project Initialization & Environment Setup
======================================================================
Goal: Set up computational environment and project structure

Environment Setup:
- Created conda environment: research_env
- Installed core packages: pandas, geopandas, rasterio, matplotlib, statsmodels
- Python 3.10.19 on Windows 11
- VS Code configured as primary IDE

Project Structure Created:
- 00_Admin/ (documentation, logs)
- 01_Data_Raw/ (original data, never modified)
- 02_Data_Intermediate/ (intermediate processing outputs)
- 03_Data_Clean/ (cleaned datasets for analysis)
- 04_Code/ (all Python scripts)
- 05_Outputs/ (regression outputs, figures)
- 06_Drafts/ (paper drafts)

GitHub Repository:
- Initialized local Git repository
- Created .gitignore (excludes large files / prevents repo bloat)
- First commit: "Initial project structure"

Key Decisions:
- Manual data download approach (API attempts for VIIRS failed)
- Focus on 2015-2024 period (10-year panel)

Status: Environment ready, awaiting data download
Next: Download RBI, EM-DAT, VIIRS datasets

======================================================================
2026-01-02 (Thu): Phase 2 - Data Acquisition (Day 1)
======================================================================
Goal: Download all three core datasets

Data Sources Acquired:

1. RBI District Banking Statistics (BSR-2)
   Location: 01_Data_Raw/RBI_Bank_Data/
   Files downloaded:
   - RBI_Deposits_2004_2017.xlsx (historical baseline)
   - RBI_Deposits_2017_2022.xlsx (5-year mid-period)
   - RBI_Deposits_2023_2024.xlsx (recent data)
   Source: Reserve Bank of India official portal
   Coverage: All districts, quarterly snapshots
   Variables: Deposits by population group (Rural/Semi-urban/Urban/Metro)

2. EM-DAT Disaster Database
   Location: 01_Data_Raw/EMDAT_Disasters/
   File: public_emdat_custom_request_2026-01-02_c149ea93-8fbf-4f6e-a8f6-3b41cc622ed0.xlsx
   Source: Centre for Research on Epidemiology of Disasters (CRED)
   Filters applied: Country=India, Disaster Type=Flood, Period=2015-2024
   Events: 70 flood events (later corrected to 69 after inspection)
   Variables: Location, dates, deaths, affected population, damage estimates

3. VIIRS Nighttime Lights (Test Tile)
   Location: 01_Data_Raw/VIIRS_NightLights/
   Test file: SVDNB_npp_20230101-20230131_75N060E_vcmcfg_v10_c202302080600
   Files extracted: .avg_rade9h.tif (avg radiance), .cvg.tif, .cf_cvg.tif
   Source: Colorado School of Mines Earth Observation Group
   Tile: 75N060E (covers all of India)
   Period tested: January 2023 (1 month)
   Note: Full download (120 months, 2015-2024) deferred to Phase 3d

Key Decisions:
- VIIRS Microsoft Planetary Computer API failed (returned 0 items)
- Pivoted to manual download from Colorado School of Mines
- Downloaded single test tile to validate format before bulk download
- RBI files span different periods, will require concatenation

Commits: 3 (data folder structure + download documentation)
Status: Phase 2 complete
Next: Phase 3a literature acquisition + Phase 3c data inspection (merge feasibility)

======================================================================
2026-01-05 (Sun): Phase 3a - Literature Acquisition
======================================================================
Goal: Build a defensible novelty baseline and assemble the core bibliography

Actions Completed:
- Searched Google Scholar, SSRN, NBER using targeted keywords
- Used Harvard HOLLIS to bypass paywalls for locked papers
- Downloaded ~15-18 papers via Zotero Chrome Connector
- Organized PDFs in 00_Admin/Literature_PDFs folder
- Fixed Zotero metadata (missing authors/dates)
- Created LiteratureTracker.xlsx with table structure

Status: Papers acquired. Ready for gap analysis reading/annotation.
Next: Phase 3b - Fill LiteratureTracker.xlsx using abstracts/intros/conclusions

======================================================================
2026-01-06 (Mon): Phase 3b - Gap Analysis
======================================================================
Goal: Confirm novelty and define “what the literature missed” in a structured way

Actions Completed:
- Read abstracts / key intro paragraphs / conclusions for the collected paper set (~15-18 papers)
- Filled LiteratureTracker.xlsx with multi-dimensional gap analysis:
  - Geographic gaps (India district-level evidence scarce / inconsistent)
  - Methodological gaps (satellite lights often used for activity proxies; migration mechanism under-tested)
  - Temporal gaps (many designs not aligned to disaster timing / dynamic panels)
  - Mechanistic gaps (banking stability often framed via credit risk; deposit/liquidity channel underemphasized)
- Confirmed novelty positioning: No paper in the reviewed set establishes the full chain:
  Climate shock → (migration proxied by VIIRS) → district-level deposit stress in India

Status: Literature phase complete. Novelty defense ready.
Next: Phase 3c - Formalize hypotheses/codebook and begin data inspection scripts

======================================================================
2026-01-07 (Tue): Phase 3c Day 0 - Conceptual Work (Mobile Only)
======================================================================
Goal: Maintain momentum and lock “definitions + hypotheses” before coding

Actions Completed:
- Laptop unavailable - executed mobile research tasks to maintain momentum
- Created Variables_Codebook_v1.md:
  - Defined variable families (outcomes, treatments, controls, networks, panel structure)
  - Defined transformations to be used in code (e.g., log changes, quarterly aggregation targets)
- Created Hypotheses_Formal_v1.md:
  - H1: Flood events → Decline in nighttime light intensity (VIIRS)
  - H2: Nighttime light decline → Decline in formal bank deposits
  - H3: Deposit decline → Increased reliance on shadow banking (timing analysis)
  - H4: Banking stress exhibits spatial contagion through district networks
- Both documents specify measurement intentions (time aggregation, geographic unit, sign expectations)

Status: Codebook + hypotheses locked. Ready to implement inspection scripts on laptop.
Next: Phase 3c Day 1 (Jan 8) - RBI/EM-DAT/VIIRS inspection scripts + merge feasibility validation

======================================================================
2026-01-08 (Wed) 19:00-21:30 PM IST: Phase 3c Day 1 - Data Inspection
======================================================================
Goal: Validate merge feasibility across 3 datasets (RBI, EM-DAT, VIIRS)

Scripts Created:
1. 02_inspect_rbi.py: RBI deposit structure inspection
   - 762 unique districts (UPPERCASE, hyphenated names)
   - 11 quarters (2023Q1-2025Q2), 4 population groups per district
   - Deposit columns at indices 7,10,13,16,19,22,25,28,31,34,37
   - Aggregation required: GROUP BY district, SUM across population groups

2. 03_inspect_emdat.py: EM-DAT flood event inspection
   - 69 flood events (2015-2024)
   - 35 events (50.7%) have district-level Admin Units data → 147 districts
   - 34 events (49.3%) have empty Admin Units (requires Location text parsing)
   - Severity measure: No. Affected (73.9% coverage)
   - Date structure: Complete, convertible to quarters

3. 04_inspect_viirs.py: VIIRS nighttime lights validation
   - Test tile (Jan 2023, 75N060E): 1.93 GB GeoTIFF, 28800×18000 pixels
   - India fully covered (60-180°E, 0-75°N extent)
   - Radiance range: 0-57.24 nW/cm²/sr (mean 0.87, median 0.50)
   - Resolution: 15 arc-second (~463m at equator)
   - Data validity: CONFIRMED

Key Findings:
- RBI: 762 districts ready for merge (standardized naming)
- EM-DAT: Geographic precision heterogeneous (50% district-level, 50% state-level)
- VIIRS: Production-ready, H1/H2 testable with district aggregation
- Expected treatment/control split: ~150 flooded districts, ~600 non-flooded
- Update (Jan 9): Admin Units are present for 57/69 events once parsed correctly (adm2_name districts + adm1_name states); only 12/69 require Location parsing.

Next Session (Phase 3c Day 2 - Jan 9):
- Parse EM-DAT Location text for missing 34 events
- Build district name harmonization crosswalk (fuzzy matching)
- Test VIIRS spatial subsetting (extract India bounding box)

Commits: 4 scripts (01_download_viirs placeholder, 02-04 inspection scripts)
Status: Phase 3c Day 1 complete

======================================================================
2026-01-09 (Fri) 17:45-18:40 PM IST: Phase 3c Day 2 - District Boundaries + EM-DAT Parsing
======================================================================
Goal: Begin district harmonization by locking district boundary polygons and extracting district/state labels from EM-DAT floods.

A) District boundary dataset acquired (GADM)
- Downloaded: gadm41_IND_shp.zip (GADM v4.1, India)
- Extracted to: 01_Data_Raw/District_Boundaries/
- Validated via geopandas load test:
  - gadm41_IND_2.shp loaded successfully
  - 676 district polygons
  - Key columns confirmed: NAME_1 (state), NAME_2 (district), geometry

B) EM-DAT district/state extraction completed
- Script created: 04_Code/06_parse_emdat_locations.py
- Outputs:
  - 02_Data_Intermediate/emdat_districts_parsed.csv
  - 05_Outputs/Logs/06_parse_emdat_log.txt
- Results:
  - Total flood events in file: 69
  - Events with usable Admin Units (adm2_name districts or fallback adm1_name states): 57 (82.6%)
  - Events missing Admin Units: 12 (17.4%) → parsed from free-text Location field
  - Geographic labels produced for all 69 events (districts and/or states)

C) Output verification
- Script created: 04_Code/07_check_output.py
- Verified:
  - emdat_districts_parsed.csv loads
  - 69/69 events have non-empty districts_final_str

Notes / Known issues
- Parsed Location text contains typos and non-district tokens in some cases (e.g., “Administrative unit not available”, “Itanagar distrci”, “Meghalaya states”).
- These will be handled during crosswalk cleaning (manual corrections + fuzzy match).

Status: District boundaries locked; EM-DAT geographic extraction complete.
Next: Build district name crosswalk (RBI ↔ GADM ↔ EM-DAT) and then generate flood exposure panel (Rule A vs Rule B).

======================================================================
2026-01-10 (Sat) 22:45-23:35 PM IST: Phase 3c Day 2.5 - Documentation Hygiene (No Coding)
======================================================================
Goal: Lock documentation language to avoid overclaiming and ensure repo docs match the actual folder structure and current phase status.

Actions Completed
A) Claim discipline updates (documentation-only)
- Core_Claims.docx: softened “first causal evidence” phrasing to “aims to provide” and made propagation wording explicitly conditional on data feasibility.
- Literature_Tracker.xlsx: softened top novelty claim from “establishes first causal evidence” to “aims to provide causal evidence consistent with.”

B) Identification / IV discipline wording (documentation-only)
- Hypotheses_Formal_v1.1.md: rewrote the H2b exclusion restriction paragraph to frame it as an identifying assumption with explicit threats (e.g., direct banking-operations disruption), without changing the empirical plan.

C) Codebook consistency (documentation-only)
- Variables_Codebook_and_Coding_Protocol_v1.1.md:
  - Updated the District Polygons status to reflect that GADM v4.1 Level-2 district boundaries are already downloaded and validated (676 districts).
  - Removed any stray [file:*] artifacts left from prior drafting.

D) README cleanup (documentation-only)
- README.md:
  - Removed [file:*] artifacts.
  - Updated repo layout to reflect current v1.1 filenames and current pipeline state.
  - Preserved RBI file extensions as .xlsx (local saved format).
  - Fixed markdown formatting issues (closed code fences) and removed duplicated outdated “Last Updated/Phase” footer lines.

Commits (documentation-only)
- Commit: “Tighten Core Claims wording”
- Commit: “Update novelty statement in Literature Tracker”
- Commit: “Clarify IV assumption language (Hypotheses v1.1)”
- Commit: “Update codebook: GADM obtained + cleanup”
- Commit: “README cleanup: consistency + formatting”

Status:
Documentation is now aligned with the current project state (Phase 3c Day 2 complete; crosswalk pending). No data or code changes were made in this session.

Next:
Phase 3c Day 3: Build district-name crosswalk (RBI ↔ GADM ↔ EM-DAT), generate district_crosswalk_draft.csv, and produce crosswalk log with match-rate stop condition check.

======================================================================
2026-01-11 (Sun) 20:10-21:00 PM IST: Phase 3c Day 3–Day 4 - Crosswalk + Flood Exposure Panel
======================================================================
Goal: Build a reproducible district-quarter flood exposure panel (Rule A/B) on a fixed geography, with logged match rates + validation checks.

Actions Completed
A) District name crosswalk (RBI ↔ GADM; EM-DAT ↔ GADM)
- Script executed: 04_Code/08_build_district_crosswalk.py
- Inputs:
  - GADM districts: 01_Data_Raw/District_Boundaries/gadm41_IND_2.shp (666 districts)
  - RBI districts: 01_Data_Raw/RBI_Bank_Data/RBI_Deposits_2023_2024.xlsx (762 districts)
  - EM-DAT parsed tokens: 02_Data_Intermediate/emdat_districts_parsed.csv (209 districts)
- Outputs:
  - 02_Data_Intermediate/district_crosswalk_draft.csv (769 rows)
  - 02_Data_Intermediate/emdat_district_matches.csv (209 rows)
  - 05_Outputs/Logs/08_build_crosswalk_log.txt
- Match rates (stop conditions):
  - RBI → GADM: 83.2% (threshold: 80%) → PASSED
  - EM-DAT → GADM: 81.3% (informational; threshold: 75%)

B) Panel skeleton construction (district × quarter)
- Script executed: 04_Code/09_build_quarterly_skeleton.py
- Output:
  - 02_Data_Intermediate/district_quarter_skeleton.csv
- Target structure: 2015Q1–2024Q4 (40 quarters), intended to be the backbone index for merges.

C) Flood exposure panel construction (Rule A vs Rule B)
- Script executed: 04_Code/10_build_flood_exposure.py
- Output:
  - 02_Data_Intermediate/flood_exposure_panel.csv
- Panel dimensions (as generated):
  - Total district-quarters: 26,640
  - Districts: 659
  - Quarters: 40
  - Date range: 2015Q1 to 2024Q4
- Exposure rates:
  - Rule A (full sample; state fallback allowed): 2,220 district-quarters (8.33%)
  - Rule B (high-precision; district-only): 272 district-quarters (1.02%)

D) Validation + summary logging
- Script executed: 04_Code/11_validate_flood_events.py
  - ✓ Event 2019-0331-IND: 33 Rule B districts correctly coded
  - ✓ Event 2023-0428-IND: State fallback triggered for HP, Delhi (Rule A only)
  - ✓ Event 2015-0504-IND: 9/10 AP/TN districts matched (90% rate)
- Script executed: 04_Code/12_summarize_flood_exposure.py
  - Output log: 05_Outputs/Logs/12_flood_exposure_summary.txt (exposure rates, top districts/states, limitations)

E) Design decision logged (geography standard)
- Logged decision: Use GADM districts as panel skeleton (not RBI districts)
- Output:
  - 05_Outputs/Logs/Phase3c_Day4_Design_Decision.txt
- Consequence recorded: RBI deposit data will be merged into GADM skeleton via district_crosswalk_draft.csv; unmatched RBI districts will be dropped or manually investigated in Phase 3d.

Known Issues / Limitations (as of Day 4)
- 46 unmatched EM-DAT location tokens remain (typos, J&K gaps, historical names).
- State-level fallback in Rule A introduces measurement error by construction.
- Historical district name changes (e.g., “Cuddapah” → “Kadapa”) are not fully resolved.

Status:
Crosswalk + quarterly skeleton + flood exposure panel are now constructed and logged (Rule A/B), with basic validation checks passed.

Next:
Phase 3d: Extract RBI deposits to long panel, bulk-download/aggregate VIIRS to districts, then merge RBI + VIIRS + flood exposure into a single district-quarter analysis dataset (03_Data_Clean), with missingness and drop logs.

======================================================================
2026-01-12 (Mon) 18:45-19:05 PM IST: Phase 3d - RBI Deposits Panel + Master Merge
======================================================================
Goal: Convert RBI deposits to a GADM district-quarter panel and merge deposits + floods into a single analysis-ready dataset.

Actions Completed
A) RBI deposits extraction (quarterly panel)
- Script executed: 04_Code/13_extract_rbi_deposits.py
- Outputs:
  - 02_Data_Intermediate/rbi_deposits_panel.csv
- Key fix: Aggregated to unique (district_gadm, state_gadm, quarter) to eliminate duplicate merge keys caused by ambiguous district-name crosswalk matches.

B) Master panel merge (skeleton + floods + deposits)
- Script executed: 04_Code/14_merge_master_panel.py
- Output:
  - 02_Data_Intermediate/master_panel_raw.csv
- Merge keys standardized to: (district_gadm, state_gadm, quarter)

C) Validation + missingness diagnostics
- Scripts executed:
  - 04_Code/15_validate_master_panel.py
  - 04_Code/16_diagnose_missing_data.py
- Output:
  - 02_Data_Intermediate/master_panel_validation_log.txt
- Findings:
  - Panel structure is balanced at 666 districts × 40 quarters = 26,640 rows.
  - Deposits blackout identified for 2016Q3–2017Q1 (2016Q3/Q4 and 2017Q1 fully missing).
  - 35 districts have 0% deposit coverage across the entire window (likely crosswalk/name-change issues).

D) Analysis sample construction (restricted sample)
- Script executed: 04_Code/17_prepare_analysis_sample.py
- Output:
  - 02_Data_Intermediate/master_panel_analysis.csv
- Restrictions applied:
  - Dropped quarters: 2016Q3, 2016Q4, 2017Q1
  - Dropped districts: 35 districts with zero deposit coverage
- Final analysis sample:
  - 631 districts × 37 quarters = 23,347 observations
  - Deposit coverage: 99.1%
  - Flood events (Rule A): 1,984 (all with deposits present in the restricted sample)

Status: Phase 3d master panel construction completed through analysis-sample output; VIIRS integration remains.
Next: Begin VIIRS monthly download/aggregation to district-quarter, then engineer regression variables (growth rates, lags) and generate descriptive tables.

======================================================================
2026-01-13 (Tue) 18:25-19:05 PM IST: Phase 3d - VIIRS Integration (Test Validation)
======================================================================
Goal: Validate VIIRS district extraction + quarterly aggregation + merge feasibility with master_panel_analysis.csv before bulk (2015–2024) processing.

A) VIIRS district extraction (Jan 2023 test)
- Script executed: 04_Code/18_extract_viirs_district_means.py
- Intended input (as coded): 01_Data_Raw/VIIRS_NightLights/SVDNB_npp_20230101-20230131_75N060E_vcmcfg_v10_c202302080600.avg_rade9h.tif
- Log: 05_Outputs/Logs/18_viirs_extraction.log
- Note: First run failed due to path mismatch ("No such file or directory"), then corrected and re-run succeeded.
- Result: GADM districts loaded: 676; extraction complete: 676 districts, 676 with data.

B) Validation checks (district overlap + coverage)
- Script executed: 04_Code/19_validate_viirs_extraction.py
- Log: 05_Outputs/Logs/19_viirs_validation.log
- Logged result: Validation complete: 624/624 districts covered (100.0%).
- Note: This denominator depends on the master panel districts loaded at runtime; treat as a computed check, not a fixed project constant.

C) Quarterly aggregation + master panel test merge (Jan 2023 only)
- Script executed: 04_Code/20_aggregate_viirs_to_quarterly.py
- Log: 05_Outputs/Logs/20_viirs_quarterly_test.log
- Logged result: Test merge complete: 2.70% coverage; Total obs: 23347, VIIRS obs: 631
- Output: 02_Data_Intermediate/master_panel_viirs_test.csv

Status:
- VIIRS test pipeline is functioning end-to-end (extract → validate → aggregate → merge test).
- Bulk monthly downloads (2015–2024) are in progress outside the repo on external storage (see local setup notes).

Next:
- Complete bulk VIIRS monthly downloads for 2015–2024.
- Generalize Script 18 to loop over all months and write a single district-month panel (02_Data_Intermediate).
- Aggregate district-month → district-quarter and merge into the master analysis sample for Phase 4 regressions.

======================================================================
2026-01-14 (Wed) 22:00-23:50 PM IST: Phase 3d Day 3 - VIIRS Bulk Downloads Complete
======================================================================
Goal: Complete bulk VIIRS monthly tile downloads (2015–2024) to external storage; document Phase 3d final execution pipeline.

A) Bulk VIIRS downloads finalized
- 120 monthly tiles downloaded manually from EOG Colorado School of Mines server
- Tile: 75N060E (covers India; 0°N-75°N, 60°E-180°E)
- Save location: E:\VIIRS_Raw_Data_75N060E\ (external storage, outside repo)
- Folder structure: Year subfolders (2015–2024) → Month subfolders (January–December) → .tgz archives
- Total compressed size: ~60–70 GB
- Download completion: Jan 13 22:00 – Jan 14 22:00 (24-hour manual download session)

B) Phase 3d script pipeline documented
- Created script skeletons (21–25) with headers, inputs/outputs, runtime estimates
- Script 21: Extract VIIRS monthly panel (81,120 rows; 6-8 hour runtime)
- Script 22: Aggregate monthly → quarterly (27,040 rows; 1-2 minutes)
- Script 23: Merge VIIRS + master panel (23,347 rows; ~90%+ coverage expected)
- Script 24: Engineer regression variables (logs, changes, lags per codebook)
- Script 25: Generate descriptive statistics (Table 1 for paper)
- Scripts documented with clear dependencies: 21 → 22 → 23 → 24 → 25

C) Project infrastructure updates
- Created Phase 3d execution plan document (00_Admin/Phase_3d_Execution_Plan.txt)
- Prepared output folder structure (03_Data_Clean/, 05_Outputs/Tables/, 05_Outputs/Figures/)
- Locked final paper title across all documentation: "Climate Shocks, Displacement, and Bank Liquidity Risk: Evidence from Night-Lights in India"
- Title changes: Migration → Displacement (more precise); Banking Stability → Bank Liquidity Risk (mechanism-specific)

D) Expected outputs (Phase 3d final)
- viirs_monthly_panel.csv: 81,120 rows (676 districts × 120 months)
- viirs_quarterly_panel.csv: 27,040 rows (676 districts × 40 quarters)
- analysis_panel_final.csv: 23,347 rows (master panel + VIIRS merged)
- regression_ready_panel.csv: same, with engineered variables
- 01_descriptive_stats.csv: Summary statistics table for paper

Status:
- Bulk downloads complete (120 months validated)
- Scripts 21–25 documented and ready for implementation
- Overnight execution planned for Script 21 (Jan 15 evening → Jan 16 morning)

Next:
- Phase 3d Day 4 (Jan 15): Implement Scripts 21–25; execute overnight extraction; produce final analysis-ready panel
- Phase 4 (Jan 16 onward): Begin regressions (H1–H4 tests)

======================================================================
2026-01-15 (Thu) 2030-2200 PM IST: Phase 3d Day 4 - Full Pipeline Implementation + Validation
======================================================================
Goal: Implement and execute Phase 3d pipeline (Scripts 21–25), validate data quality before regressions.

A) Script 21: Full VIIRS extraction (COMPLETED)
- Executed 04_Code/21_extract_viirs_full_panel.py
- Runtime: ~60 minutes (much faster than 6-8hr estimate)
- Input: 120 monthly VIIRS tiles from F:\Jaseel\VIIRS_Raw_Data_75N060E\
- Output: 02_Data_Intermediate/viirs_monthly_panel.csv (81,120 rows)
- Status: Extraction complete, but contains duplicates (see validation below)

B) Scripts 22-25: Data pipeline (IMPLEMENTED, execution deferred)
- 22_aggregate_viirs_quarterly.py: Monthly → quarterly aggregation
- 23_merge_viirs_master.py: VIIRS + deposits + floods merge
- 24_engineer_regression_variables.py: Logs, changes, lags
- 25_descriptive_statistics.py: Table 1 summary stats
- Status: Code complete, awaiting validated input data

C) Scripts 27-29: Phase 4 regression scripts (IMPLEMENTED, execution deferred)
- 27_regression_H1_first_stage.py: Floods → Lights (first stage)
- 28_regression_H2_iv2sls.py: Lights → Deposits (IV 2SLS)
- 29_regression_H3_timing.py: Distributed lags, timing analysis
- Status: Code complete, awaiting analysis-ready panel

D) Script 26: VIIRS monthly validation (EXECUTED - FAILED)
- Created 04_Code/26_validate_viirs_monthly.py
- Comprehensive 8-check validation of viirs_monthly_panel.csv
- Result: VALIDATION FAILED (3 checks failed, 5 passed)
  - ✓ PASS: Dimensions (81,120 rows)
  - ✓ PASS: Required columns present
  - ✗ FAIL: District coverage (expected 676, got 659 unique)
  - ✓ PASS: Temporal coverage (120 months, 2015-2024)
  - ✓ PASS: No NaN values
  - ✓ PASS: No Inf values
  - ✓ PASS: Valid radiance range (0-41.33)
  - ✗ FAIL: Unbalanced panel (16 districts with ≠ 120 obs)
- Diagnostic finding: One district (Kinnaur) has 360 obs (3× expected)
- Output: 05_Outputs/Logs/26_viirs_monthly_validation.txt

E) Script 21b: Diagnostic for duplicate extractions (EXECUTED)
- Created 04_Code/21b_diagnose_viirs_duplicates.py (temporary debug script)
- Compared GADM districts (expected) vs VIIRS panel (actual)
- Key findings:
  - GADM shapefile has 676 rows but only 659 unique district names
  - 16 districts have multipolygon geometries (2-3 geometries per district)
  - Script 21 iterated over rows (676) instead of unique districts (659)
  - Result: Duplicate extractions for multipolygon districts
  - Kinnaur: 3 geometries → 360 obs (120 months × 3)
  - Bilaspur, Aurangabad, etc.: 2 geometries → 240 obs (120 months × 2)
- Root cause identified: Missing dissolve step before extraction loop
- Output: Console diagnostic report

F) Fix documentation: Script_21_Fix_Notes.txt
- Created 00_Admin/Script_21_Fix_Notes.txt
- Documents multipolygon duplicate extraction issue
- Provides exact code fix:
  ```python
  districts_gdf = districts_gdf.dissolve(by='NAME_2', as_index=False)

======================================================================
2026-01-16 (Fri) 18:40-20:45 PM IST: Phase 4 - Full Pipeline Execution + H1–H4 Regressions
======================================================================
Goal: Resolve VIIRS duplicate/multipolygon issue, run the full post-VIIRS pipeline (Scripts 22–26), and execute Phase 4 regressions (H1–H4) with saved tables + logs.

Actions Completed

A) VIIRS duplicate fix + rerun extraction (Script 21)
- Implemented the multipolygon fix documented on Day 4 (dissolve districts before looping).
- Re-ran: 04_Code/21_extract_viirs_full_panel.py
- Output regenerated:
  - 02_Data_Intermediate/viirs_monthly_panel.csv

B) VIIRS quarterly aggregation (Script 22)
- Executed: 04_Code/22_aggregate_viirs_quarterly.py
- Input: 02_Data_Intermediate/viirs_monthly_panel.csv
- Output:
  - 02_Data_Intermediate/viirs_quarterly_panel.csv
- Log:
  - 05_Outputs/Logs/22_viirs_quarterly

C) Merge VIIRS into master analysis panel (Script 23)
- Executed: 04_Code/23_merge_viirs_master.py
- Inputs:
  - 02_Data_Intermediate/master_panel_analysis.csv
  - 02_Data_Intermediate/viirs_quarterly_panel.csv
- Output:
  - 03_Data_Clean/analysis_panel_final.csv
- Log:
  - 05_Outputs/Logs/23_viirs_master_merge

D) Regression variable engineering (Script 24)
- Executed: 04_Code/24_engineer_regression_variables.py
- Input:
  - 03_Data_Clean/analysis_panel_final.csv
- Output:
  - 03_Data_Clean/regression_panel_final.csv
- Key constructions (as per codebook intent):
  - Quarterly changes (deposits + lights), logs, and lagged flood indicators.
- Log:
  - 05_Outputs/Logs/24_variable_engineering

E) Descriptive statistics table generated (Script 25)
- Executed: 04_Code/25_descriptive_statistics.py
- Output:
  - 05_Outputs/Tables/01_descriptive_stats.csv
- Log:
  - 05_Outputs/Logs/25_descriptive_summary

F) Post-fix VIIRS validation (Script 26)
- Executed: 04_Code/26_validate_viirs_monthly.py
- Purpose: confirm panel balance + district coverage after the multipolygon fix.
- Log:
  - 05_Outputs/Logs/26_viirs_monthly_validation

G) Phase 4 regressions executed (H1–H4)
H1) Floods → Nighttime lights (first stage)
- Executed: 04_Code/27_regression_H1_first_stage.py
- Outputs:
  - 05_Outputs/Tables/02_H1_first_stage.csv
  - 05_Outputs/Logs/27_H1_regression.txt
  - 05_Outputs/Logs/27_H1_regression_full.txt

H2) IV 2SLS: Lights → Deposits, instrumented by floods
- Executed: 04_Code/28_regression_H2_iv2sls.py
- Outputs:
  - 05_Outputs/Tables/03_H2_iv2sls.csv
  - 05_Outputs/Logs/28_H2_iv_results

H3) Timing / distributed lag effects
- Executed: 04_Code/29_regression_H3_timing.py
- Outputs:
  - 05_Outputs/Tables/04_H3_timing.csv
  - 05_Outputs/Logs/29_H3_timing

H4) Heterogeneity analysis
- Executed: 04_Code/30_regression_H4_heterogeneity.py
- Outputs:
  - 05_Outputs/Tables/05_H4_heterogeneity.csv
  - 05_Outputs/Logs/30_H4_heterogeneity

Known Limitations / Warnings (do not overclaim)
- H2 IV credibility depends on first-stage strength; weak-instrument risk must be reported directly (F-stat + p-values) rather than interpreted away.
- All inference statements must clarify whether SEs are clustered by district; if not clustered, treat p-values as potentially optimistic.
- Flood exposure Rule A includes state-level fallback, which mechanically introduces false positives and attenuates coefficients toward zero.

Status:
- Phase 4 execution complete: final cleaned panels produced + all H1–H4 scripts executed with saved CSV tables and text logs.

Next:
- Robustness: re-run key specs with district-clustered SEs; run “Rule B only” (district-precision floods) as a credibility check.
- Begin Phase 5 writing: Results section anchored on Tables 02–05, with explicit identification/limitations language.

======================================================================
END OF LOG - Last Updated: 2026-01-16 21:55 PM IST
======================================================================
